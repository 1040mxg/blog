---
layout: post
title: CIFAR-10 Image Classifier
author: Michelle Gong
permalink: posts/2021-03-30-cifar
published: true
tags: kaggle
---

[Jupyter Notebook:](https://colab.research.google.com/drive/1H4CMCkfj26ieoxvXJCfVlNSjN2p8ptBy?usp=sharing)
Initial score: 0.77511 ||
Score with modified dataset: 0.77511 (remained same)

Note: all text on this page is also in the notebook linked above. I highly recommend going directly to the notebook in order to see the analysis in-context with the associated graphs and charts.

The challenge for this task was to improve upon the average accuracy of a CIFAR-10 image classifier, using the official PyTorch CIFAR-10 tutorial as a starting point: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py

In order to try and improve accuracy, I experimented with various hyperparameters, particulary conv2d shape and number of layers.

Steps:
Set-up:
Loaded and normalised CIFAR10 training/test datasets using torchvision
Set up two lists "networkAcc" and "classAcc" to record results across experiments
Build convnet
Trained and tested

Experiments involved:

Runs 1-3: changed the shape of conv2d. Resulted in a 7% increase in overall network accuracy, but some class accuracy decreased while others increased.
Runs 4-5: using the different conv2d shapes from 1-3, added them on as additional layers. The intent was to go up to 4 layers total, but as the accuracy began to flunctuate, and the training time became noticeably longer, this did not seem the best way forward.

In the end, I was able to improve upon the base accuracy by 9.29%.

